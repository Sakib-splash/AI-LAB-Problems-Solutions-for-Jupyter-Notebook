{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f65c5c9-aa2e-4602-b9ce-1a5fc65de3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New weights found, iteration: 1 loss: 0.3970750876967418\n",
      "New weights found, iteration: 3 loss: 0.3790454299796513\n",
      "New weights found, iteration: 4 loss: 0.3539406867600283\n",
      "New weights found, iteration: 5 loss: 0.32014203490476434\n",
      "New weights found, iteration: 7 loss: 0.31758208312392167\n",
      "New weights found, iteration: 9 loss: 0.29335788774403126\n",
      "New weights found, iteration: 10 loss: 0.2744626161705824\n",
      "New weights found, iteration: 12 loss: 0.2722334896172951\n",
      "New weights found, iteration: 15 loss: 0.23165273343473766\n",
      "New weights found, iteration: 18 loss: 0.21934453134448004\n",
      "New weights found, iteration: 21 loss: 0.1604480672043302\n",
      "New weights found, iteration: 23 loss: 0.15893749615022412\n",
      "New weights found, iteration: 26 loss: 0.156638418862746\n",
      "New weights found, iteration: 28 loss: 0.13739536264956043\n",
      "New weights found, iteration: 29 loss: 0.12884548843650712\n",
      "New weights found, iteration: 31 loss: 0.12372850513690464\n",
      "New weights found, iteration: 33 loss: 0.11839035173376306\n",
      "New weights found, iteration: 35 loss: 0.10972278326122509\n",
      "New weights found, iteration: 38 loss: 0.0957815887892115\n",
      "New weights found, iteration: 40 loss: 0.08412209009857227\n",
      "New weights found, iteration: 45 loss: 0.08024823173354842\n",
      "New weights found, iteration: 49 loss: 0.07724150687255177\n",
      "New weights found, iteration: 52 loss: 0.07699494277202992\n",
      "New weights found, iteration: 56 loss: 0.0711499418288936\n",
      "New weights found, iteration: 57 loss: 0.06535198939570186\n",
      "New weights found, iteration: 62 loss: 0.05861069936206513\n",
      "New weights found, iteration: 68 loss: 0.05725021339236534\n",
      "New weights found, iteration: 72 loss: 0.04984405890885328\n",
      "[[0.03784183]\n",
      " [0.24108014]\n",
      " [0.22567782]\n",
      " [0.70184883]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Use sigmoidal activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Creating loss function\n",
    "def loss(predicted, actual):\n",
    "    return np.mean((predicted - actual) ** 2)\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size = 3\n",
    "output_size = 1\n",
    "\n",
    "# Initialize the weights and biases\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.random.randn(hidden_size)\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.random.randn(output_size)\n",
    "\n",
    "# Define the input for the AND gate\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Define the target output for the AND gate\n",
    "target = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "# final_output\n",
    "final_output=None\n",
    "\n",
    "# Create some variables to track the best loss and the associated weights and biases\n",
    "best_loss = float('inf')\n",
    "best_W1 = None\n",
    "best_b1 = None\n",
    "best_W2 = None\n",
    "best_b2 = None\n",
    "\n",
    "iteration=0\n",
    "\n",
    "while(best_loss>=0.05):\n",
    "    # Forward pass\n",
    "    hidden_layer_output = np.dot(x, W1) + b1\n",
    "    output = sigmoid(np.dot(hidden_layer_output, W2) + b2)\n",
    "\n",
    "    # save final output\n",
    "    final_output=output\n",
    "\n",
    "    # Loss calculation\n",
    "    current_loss = loss(output, target)\n",
    "\n",
    "    iteration=iteration+1\n",
    "\n",
    "    if current_loss < best_loss:\n",
    "        print('New weights found, iteration:', iteration, 'loss:', current_loss)\n",
    "        # Save current weights and biases as the best ones so far\n",
    "        best_loss = current_loss\n",
    "        best_W1 = W1.copy()\n",
    "        best_b1 = b1.copy()\n",
    "        best_W2 = W2.copy()\n",
    "        best_b2 = b2.copy()\n",
    "    else:\n",
    "        # Revert weights and biases to the previous best values\n",
    "        W1 = best_W1.copy()\n",
    "        b1 = best_b1.copy()\n",
    "        W2 = best_W2.copy()\n",
    "        b2 = best_b2.copy()\n",
    "\n",
    "    # Update weights with small random values\n",
    "    W1 += 0.09 * np.random.randn(input_size, hidden_size)\n",
    "    b1 += 0.09 * np.random.randn(hidden_size)\n",
    "    W2 += 0.09 * np.random.randn(hidden_size, output_size)\n",
    "    b2 += 0.09 * np.random.randn(output_size)\n",
    "\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2559220-c941-4851-bb72-4836f9b0ba32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best weights found, iteration: 1 loss: 0.30631040762554806\n",
      "New best weights found, iteration: 3 loss: 0.3058560919176789\n",
      "New best weights found, iteration: 4 loss: 0.3010623374368908\n",
      "New best weights found, iteration: 5 loss: 0.29464716128930385\n",
      "New best weights found, iteration: 6 loss: 0.2868604154223311\n",
      "New best weights found, iteration: 10 loss: 0.26235010492508587\n",
      "New best weights found, iteration: 13 loss: 0.2550886405542417\n",
      "New best weights found, iteration: 16 loss: 0.2455867917824139\n",
      "New best weights found, iteration: 18 loss: 0.23337745686408357\n",
      "New best weights found, iteration: 19 loss: 0.2181556958302579\n",
      "New best weights found, iteration: 22 loss: 0.20676119512733832\n",
      "New best weights found, iteration: 23 loss: 0.19377455346186107\n",
      "New best weights found, iteration: 24 loss: 0.19263649413583217\n",
      "New best weights found, iteration: 28 loss: 0.19089109504046795\n",
      "New best weights found, iteration: 30 loss: 0.1847045876703139\n",
      "New best weights found, iteration: 37 loss: 0.18063300590637782\n",
      "New best weights found, iteration: 38 loss: 0.17151653766534763\n",
      "New best weights found, iteration: 39 loss: 0.16980100765539335\n",
      "New best weights found, iteration: 41 loss: 0.1614725156857559\n",
      "New best weights found, iteration: 45 loss: 0.15460049028567513\n",
      "New best weights found, iteration: 47 loss: 0.15063047249157796\n",
      "New best weights found, iteration: 50 loss: 0.1458625825567233\n",
      "New best weights found, iteration: 51 loss: 0.1418696736280786\n",
      "New best weights found, iteration: 52 loss: 0.14080492256730948\n",
      "New best weights found, iteration: 55 loss: 0.13134385058178183\n",
      "New best weights found, iteration: 56 loss: 0.1308768106769787\n",
      "New best weights found, iteration: 58 loss: 0.1256819692230299\n",
      "New best weights found, iteration: 61 loss: 0.12345993902536008\n",
      "New best weights found, iteration: 62 loss: 0.11447419509969159\n",
      "New best weights found, iteration: 63 loss: 0.11022733214869346\n",
      "New best weights found, iteration: 69 loss: 0.1026972940417843\n",
      "New best weights found, iteration: 70 loss: 0.0997956154227022\n",
      "New best weights found, iteration: 74 loss: 0.09943445565219043\n",
      "New best weights found, iteration: 77 loss: 0.09635242281525934\n",
      "New best weights found, iteration: 78 loss: 0.09633148040930865\n",
      "New best weights found, iteration: 80 loss: 0.09565628908495521\n",
      "New best weights found, iteration: 82 loss: 0.09525752282077046\n",
      "New best weights found, iteration: 84 loss: 0.09223287390214091\n",
      "New best weights found, iteration: 85 loss: 0.09154140784057802\n",
      "New best weights found, iteration: 86 loss: 0.08476553377110646\n",
      "New best weights found, iteration: 89 loss: 0.08468297025046588\n",
      "New best weights found, iteration: 90 loss: 0.0797642441244687\n",
      "New best weights found, iteration: 94 loss: 0.07906686987359063\n",
      "New best weights found, iteration: 96 loss: 0.07852442193840614\n",
      "New best weights found, iteration: 98 loss: 0.0783241784331688\n",
      "New best weights found, iteration: 100 loss: 0.07526095051951436\n",
      "New best weights found, iteration: 101 loss: 0.07030944663305627\n",
      "New best weights found, iteration: 105 loss: 0.06829703189935513\n",
      "New best weights found, iteration: 110 loss: 0.06713201325938793\n",
      "New best weights found, iteration: 120 loss: 0.06479173767368773\n",
      "New best weights found, iteration: 121 loss: 0.06335709524557405\n",
      "New best weights found, iteration: 123 loss: 0.06225505344526415\n",
      "New best weights found, iteration: 128 loss: 0.06130161048778801\n",
      "New best weights found, iteration: 131 loss: 0.06069726398828569\n",
      "New best weights found, iteration: 132 loss: 0.056281347358591055\n",
      "New best weights found, iteration: 134 loss: 0.05207712216197255\n",
      "New best weights found, iteration: 135 loss: 0.05206918836903969\n",
      "New best weights found, iteration: 136 loss: 0.05123193625630423\n",
      "New best weights found, iteration: 139 loss: 0.05029469784393712\n",
      "New best weights found, iteration: 147 loss: 0.04754337037661319\n",
      "Final output after training:\n",
      "[[0.03165987]\n",
      " [0.27098421]\n",
      " [0.17666888]\n",
      " [0.70926507]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Use sigmoidal activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Creating loss function\n",
    "def loss(predicted, actual):\n",
    "    return np.mean((predicted - actual) ** 2)\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "# Initialize the weights and biases\n",
    "W1 = np.random.randn(input_size, output_size)\n",
    "b1 = np.random.randn(output_size)\n",
    "\n",
    "# Define the input for the AND gate\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Define the target output for the AND gate\n",
    "target = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "# Final output placeholder\n",
    "final_output = None\n",
    "\n",
    "# Create some variables to track the best loss and the associated weights and biases\n",
    "best_loss = float('inf')\n",
    "best_W1 = None\n",
    "best_b1 = None\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "while best_loss >= 0.05:\n",
    "    # Forward pass\n",
    "    final_output = np.dot(x, W1) + b1\n",
    "    output = sigmoid(final_output)\n",
    "\n",
    "    # Loss calculation\n",
    "    current_loss = loss(output, target)\n",
    "\n",
    "    iteration += 1\n",
    "\n",
    "    if current_loss < best_loss:\n",
    "        print('New best weights found, iteration:', iteration, 'loss:', current_loss)\n",
    "        # Save current weights and biases as the best ones so far\n",
    "        best_loss = current_loss\n",
    "        best_W1 = W1.copy()\n",
    "        best_b1 = b1.copy()\n",
    "    else:\n",
    "        # Revert weights and biases to the previous best values\n",
    "        W1 = best_W1.copy()\n",
    "        b1 = best_b1.copy()\n",
    "\n",
    "    # Update weights with small random values\n",
    "    W1 += 0.09 * np.random.randn(input_size, output_size)\n",
    "    b1 += 0.09 * np.random.randn(output_size)\n",
    "\n",
    "print(\"Final output after training:\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab80861d-42f0-4663-9aaf-fcade1724c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best weights found, iteration: 1 loss: 0.1993831157431282\n",
      "New best weights found, iteration: 2 loss: 0.19627384698252398\n",
      "New best weights found, iteration: 3 loss: 0.18882888798210712\n",
      "New best weights found, iteration: 4 loss: 0.1807434604176942\n",
      "New best weights found, iteration: 6 loss: 0.18034024544594\n",
      "New best weights found, iteration: 7 loss: 0.17095105258674836\n",
      "New best weights found, iteration: 10 loss: 0.1670553401741059\n",
      "New best weights found, iteration: 11 loss: 0.16063851954697952\n",
      "New best weights found, iteration: 13 loss: 0.15465990471520039\n",
      "New best weights found, iteration: 14 loss: 0.14510403116467332\n",
      "New best weights found, iteration: 15 loss: 0.13903411502531265\n",
      "New best weights found, iteration: 16 loss: 0.1340175183090801\n",
      "New best weights found, iteration: 20 loss: 0.12159768656651165\n",
      "New best weights found, iteration: 24 loss: 0.1212760455136235\n",
      "New best weights found, iteration: 25 loss: 0.11338539936278044\n",
      "New best weights found, iteration: 27 loss: 0.10693023416044999\n",
      "New best weights found, iteration: 29 loss: 0.09960312324988953\n",
      "New best weights found, iteration: 30 loss: 0.09784564757026878\n",
      "New best weights found, iteration: 32 loss: 0.09227408366363371\n",
      "New best weights found, iteration: 36 loss: 0.09163635479303266\n",
      "New best weights found, iteration: 38 loss: 0.09130822372432683\n",
      "New best weights found, iteration: 44 loss: 0.09061924902080144\n",
      "New best weights found, iteration: 46 loss: 0.08561067348305693\n",
      "New best weights found, iteration: 47 loss: 0.08341116115275132\n",
      "New best weights found, iteration: 49 loss: 0.08335123710811768\n",
      "New best weights found, iteration: 51 loss: 0.08212630081249606\n",
      "New best weights found, iteration: 53 loss: 0.08111400896339983\n",
      "New best weights found, iteration: 54 loss: 0.07833309116188078\n",
      "New best weights found, iteration: 55 loss: 0.07626045611146515\n",
      "New best weights found, iteration: 56 loss: 0.06973169370693308\n",
      "New best weights found, iteration: 60 loss: 0.06437076881957798\n",
      "New best weights found, iteration: 65 loss: 0.06382124150272041\n",
      "New best weights found, iteration: 66 loss: 0.06096606162940235\n",
      "New best weights found, iteration: 67 loss: 0.05790668690711047\n",
      "New best weights found, iteration: 69 loss: 0.05747658109383839\n",
      "New best weights found, iteration: 70 loss: 0.05483988351167682\n",
      "New best weights found, iteration: 76 loss: 0.05440202009084536\n",
      "New best weights found, iteration: 78 loss: 0.053420854113265345\n",
      "New best weights found, iteration: 79 loss: 0.05251729363514708\n",
      "New best weights found, iteration: 85 loss: 0.05196184166975813\n",
      "New best weights found, iteration: 92 loss: 0.04868937023654997\n",
      "New best weights found, iteration: 94 loss: 0.04747301748490178\n",
      "New best weights found, iteration: 99 loss: 0.0460630284276072\n",
      "Final output after training:\n",
      "[[0.03350485]\n",
      " [0.25874082]\n",
      " [0.26014557]\n",
      " [0.77975693]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def loss(predicted, actual):\n",
    "    return np.mean((predicted - actual) ** 2)\n",
    "\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "W1 = np.random.randn(input_size, output_size)\n",
    "b1 = np.random.randn(output_size)\n",
    "\n",
    "# Define the input for the AND gate\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "target = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "final_output = None\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_W1 = None\n",
    "best_b1 = None\n",
    "\n",
    "\n",
    "num_iterations = 100\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    final_output = np.dot(x, W1) + b1\n",
    "    output = sigmoid(final_output)\n",
    "\n",
    "    current_loss = loss(output, target)\n",
    "\n",
    "    if current_loss < best_loss:\n",
    "        print('New best weights found, iteration:', iteration + 1, 'loss:', current_loss)\n",
    "        best_loss = current_loss\n",
    "        best_W1 = W1.copy()\n",
    "        best_b1 = b1.copy()\n",
    "    else:\n",
    "        W1 = best_W1.copy()\n",
    "        b1 = best_b1.copy()\n",
    "\n",
    "    W1 += 0.09 * np.random.randn(input_size, output_size)\n",
    "    b1 += 0.09 * np.random.randn(output_size)\n",
    "\n",
    "W1 = best_W1\n",
    "b1 = best_b1\n",
    "\n",
    "final_output = np.dot(x, W1) + b1\n",
    "output = sigmoid(final_output)\n",
    "\n",
    "print(\"Final output after training:\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177dcdf3-a499-4cf6-970f-2076b2962428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad19db0-9aac-4d89-8d2a-75f9a36f9df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
